{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_neighbors_size(row, **kwargs):\n",
    "\n",
    "    return kwargs['graph'].get_neighbors_size(row[\"node1\"])\n",
    "\n",
    "def cal_common_neighbors(row, **kwargs):\n",
    "\n",
    "    return kwargs['graph'].common_neighbors(row[\"node1\"], row[\"node2\"])\n",
    "\n",
    "def cal_jaccard_coefficient(row, **kwargs):\n",
    "\n",
    "    return kwargs['graph'].jaccard_coefficient(row[\"node1\"], row[\"node2\"])\n",
    "\n",
    "def cal_preferential_attachment(row, **kwargs):\n",
    "\n",
    "    return kwargs['graph'].preferential_attachment(row[\"node1\"], row[\"node2\"])\n",
    "\n",
    "socre_func = {\n",
    "    \"dir\": cal_neighbors_size,\n",
    "    \"common_neighbors\": cal_common_neighbors,\n",
    "    \"jaccard_coefficient\": cal_jaccard_coefficient,\n",
    "    \"preferential_attachment\": cal_preferential_attachment\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train = pd.read_csv(r'Data/new_train_data.csv', dtype = {'node1': 'int32', 'node2': 'int32', 'label': 'int32'})\n",
    "test = pd.read_csv(r'Data/new_test_data.csv', dtype = {'node1': 'int32', 'node2': 'int32'})\n",
    "\n",
    "train = train[train.node1 != train.node2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import Graph\n",
    "from core import ScoreFuncPipeline\n",
    "from core import DegreeBased\n",
    "\n",
    "sp = ScoreFuncPipeline(**socre_func)\n",
    "\n",
    "graph_out = Graph()\n",
    "graph_in  = Graph()\n",
    "\n",
    "for _, row in train[train.label==1].iterrows():\n",
    "    graph_out.add_edge(row['node1'], row['node2'])\n",
    "    graph_in.add_edge(row['node2'], row['node1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sparsification**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Degree Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "x_train_drop = ['node1', 'node2', 'label']\n",
    "y_train = ['label']\n",
    "x_test_drop = ['node_pair_id', 'node1', 'node2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_ensemble = pd.DataFrame()\n",
    "test_ensemble = pd.DataFrame()\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, name):\n",
    "    model.fit(x_train, y_train)\n",
    "    train_ensemble[name] = model.predict(x_train)\n",
    "    test_ensemble[name] = model.predict(x_test)\n",
    "\n",
    "def train_model_out_in(train, test, name, rs=0, lr_penalty='l2', lr_solver='lbfgs'):\n",
    "    train_model(\n",
    "        model=LogisticRegression(random_state=rs, penalty=lr_penalty, solver=lr_solver),\n",
    "        x_train=train.drop(columns=x_train_drop),\n",
    "        y_train=train[y_train],\n",
    "        x_test=test.drop(columns=x_test_drop),\n",
    "        name=f\"lr_{name}\"\n",
    "    )\n",
    "\n",
    "    # train_model(\n",
    "    #     model=AdaBoostClassifier(),\n",
    "    #     x_train=train.drop(columns=x_train_drop),\n",
    "    #     y_train=train[y_train],\n",
    "    #     x_test=test.drop(columns=x_test_drop),\n",
    "    #     name=f\"abc_{name}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = [\n",
    "    (\"lbfgs\", \"l2\"),\n",
    "    (\"lbfgs\", \"none\"),\n",
    "    (\"liblinear\", \"l1\"),\n",
    "    (\"liblinear\", \"l2\"),\n",
    "    (\"newton-cg\", \"l2\"),\n",
    "    (\"sag\", \"l2\"),\n",
    "    (\"saga\", \"l1\"),\n",
    "    (\"saga\", \"l2\"),\n",
    "    # (\"saga\", \"elasticnet\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree_based_1_le_l2_lbfgs\n",
      "degree_based_1_le_none_lbfgs\n",
      "degree_based_1_le_l1_liblinear\n",
      "degree_based_1_le_l2_liblinear\n",
      "degree_based_1_le_l2_newton-cg\n",
      "degree_based_1_le_l2_sag\n",
      "degree_based_1_le_l1_saga\n",
      "degree_based_1_le_l2_saga\n",
      "degree_based_1_ge_l2_lbfgs\n",
      "degree_based_1_ge_none_lbfgs\n",
      "degree_based_1_ge_l1_liblinear\n",
      "degree_based_1_ge_l2_liblinear\n",
      "degree_based_1_ge_l2_newton-cg\n",
      "degree_based_1_ge_l2_sag\n",
      "degree_based_1_ge_l1_saga\n",
      "degree_based_1_ge_l2_saga\n",
      "degree_based_1_eq_l2_lbfgs\n",
      "degree_based_1_eq_none_lbfgs\n",
      "degree_based_1_eq_l1_liblinear\n",
      "degree_based_1_eq_l2_liblinear\n",
      "degree_based_1_eq_l2_newton-cg\n",
      "degree_based_1_eq_l2_sag\n",
      "degree_based_1_eq_l1_saga\n",
      "degree_based_1_eq_l2_saga\n",
      "degree_based_1_ne_l2_lbfgs\n",
      "degree_based_1_ne_none_lbfgs\n",
      "degree_based_1_ne_l1_liblinear\n",
      "degree_based_1_ne_l2_liblinear\n",
      "degree_based_1_ne_l2_newton-cg\n",
      "degree_based_1_ne_l2_sag\n",
      "degree_based_1_ne_l1_saga\n",
      "degree_based_1_ne_l2_saga\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "\n",
    "# degrees = [i for i in range(1, 10)]\n",
    "degrees = [1]\n",
    "operations = [operator.le, operator.ge, operator.eq, operator.ne]\n",
    "\n",
    "degree_based_combinations = list(itertools.product(degrees, operations, lr_params))\n",
    "\n",
    "for degree, operation, (s, p) in degree_based_combinations:\n",
    "\n",
    "    print(f\"degree_based_{degree}_{operation.__name__}_{p}_{s}\")\n",
    "    \n",
    "    graph_out_db = DegreeBased(graph=graph_out, degree=degree, operation=operation).fit()\n",
    "    train_db_out, test_db_out = sp.transform(graph=graph_out_db, df_train=train, df_test=test)\n",
    "\n",
    "    graph_in_db = DegreeBased(graph=graph_in, degree=degree, operation=operation).fit()\n",
    "    train_db_in, test_db_in = sp.transform(graph=graph_in_db, df_train=train, df_test=test)\n",
    "\n",
    "    train_model_out_in(train_db_out, test_db_out, f\"degree_based_{degree}_{operation.__name__}_{p}_{s}_out\", lr_penalty=p, lr_solver=s)\n",
    "    train_model_out_in(train_db_in, test_db_in, f\"degree_based_{degree}_{operation.__name__}_{p}_{s}_in\", lr_penalty=p, lr_solver=s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Walk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_walk_0.1_0.1_0_l2_lbfgs\n",
      "random_walk_0.1_0.1_0_none_lbfgs\n",
      "random_walk_0.1_0.1_0_l1_liblinear\n",
      "random_walk_0.1_0.1_0_l2_liblinear\n",
      "random_walk_0.1_0.1_0_l2_newton-cg\n",
      "random_walk_0.1_0.1_0_l2_sag\n",
      "random_walk_0.1_0.1_0_l1_saga\n",
      "random_walk_0.1_0.1_0_l2_saga\n"
     ]
    }
   ],
   "source": [
    "from core import RandomWalk\n",
    "\n",
    "# random_states = [i for i in range(0, 2)]\n",
    "# node1_dropouts = [i/100 for i in range(1, 20)]\n",
    "# neighbors_dropouts = [i/50 for i in range(10, 35, 5)]\n",
    "random_states = [i for i in range(0, 1)]\n",
    "node1_dropouts = [0.1]\n",
    "neighbors_dropouts = [0.1]\n",
    "\n",
    "dropout_combinations = list(itertools.product(random_states, node1_dropouts, neighbors_dropouts, lr_params))\n",
    "\n",
    "for rs, node1_dropout, neighbor_dropout, (s, p) in dropout_combinations:\n",
    "    print(f\"random_walk_{node1_dropout}_{neighbor_dropout}_{rs}_{p}_{s}\")\n",
    "    graph_out_rw = RandomWalk.fit(graph=graph_out, node1_dropout=node1_dropout, neighbor_dropout=neighbor_dropout)\n",
    "    train_rw_out, test_rw_out = sp.transform(graph=graph_out_rw, df_train=train, df_test=test)\n",
    "\n",
    "    graph_in_rw = RandomWalk.fit(graph=graph_in, node1_dropout=node1_dropout, neighbor_dropout=neighbor_dropout)\n",
    "    train_rw_in, test_rw_in = sp.transform(graph=graph_in_rw, df_train=train, df_test=test)\n",
    "\n",
    "    train_model_out_in(train_rw_out, test_rw_out, f\"random_walk_{node1_dropout}_{neighbor_dropout}_{rs}_{p}_{s}_out\", rs=rs, lr_penalty=p, lr_solver=s)\n",
    "    train_model_out_in(train_rw_in, test_rw_in, f\"random_walk_{node1_dropout}_{neighbor_dropout}_{rs}_{p}_{s}_in\", rs=rs, lr_penalty=p, lr_solver=s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3325\n",
       "0    2675\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ensemble.apply(lambda x: 1 if x.sum() > len(test_ensemble.columns)/2 else 0, axis = 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3325\n",
       "0    2675\n",
       "Name: ans, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = pd.DataFrame()\n",
    "ans['node_pair_id'] = test['node_pair_id'].to_list()\n",
    "ans['ans'] = test_ensemble.apply(lambda x: 1 if x.sum() > len(test_ensemble.columns)/2 else 0, axis = 1)\n",
    "ans.ans.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('ans.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
